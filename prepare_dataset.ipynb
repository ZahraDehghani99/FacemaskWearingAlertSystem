{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZahraDehghani99/FacemaskWearingAlertSystem/blob/main/prepare_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqoIpCwnxyjR"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F3XcU0LUxyjd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from imutils import paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLSIxtlxx8IK",
        "outputId": "4c424c38-5da2-4916-d7ec-e80a2b1b5628"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## for unmount drive\n",
        "# from google.colab import drive\n",
        "# drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "iqWlsKR6fPRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbHETcNwxyjV"
      },
      "source": [
        "## RMFD "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make data balance"
      ],
      "metadata": {
        "id": "_VES2zOYik5w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdeGkcBIxyjY"
      },
      "source": [
        "در مقاله ذکر شده که این مجموعه دادگان شامل ۵۰۰۰ عکس باماسک و ۵۰۰۰ عکس بدون ماسک است. اما با مراجعه به صفحه ی گیت هاب مربوط به مقاله ی این دادگان، انواع مختلفی از دیتاست را مشاهده می کنیم که در برخی از آن ها تصاویر با ماسک از تصاویر بدون ماسک جدا نشده اند. تنها داده ای که نزدیک به اظهارات مقاله است [این](https://drive.google.com/file/d/1UlOk6EtiaXTHylRUx2mySgvJX9ycoeBp/view) لینک می باشد.\n",
        "\n",
        "طبق توضیحات گیت هاب این پوشه شامل ۵۰۰۰ عکس انسان های مختلف با ماسک و ۹۰۰۰۰ عکس ار انسان های مختلف بدون ماسک است. پس از دانلود این مجموعه دادگان متوجه می شویم برخلاف \n",
        "چیزی که در گیت هاب دادگان ذکر شده بود تنها ۲۲۰۳ عکس با ماسک و ۹۰۴۶۸ عکس بدون ماسک داریم. برای اینکه مانند مقاله کلاس بندی متوازنی داشته باشیم تمام  داده های با ماسک را استفاده می کنیم و به صورت رندوم ۲۲۰۳ عکس نیز ار داده های بدون ماسک انتخاب می کنیم. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xnkv8pVhxyjh"
      },
      "outputs": [],
      "source": [
        "RMFD_PATH = \"/content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/RMFD/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read with-mask images"
      ],
      "metadata": {
        "id": "AsyEpgKPiwrs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVAqCT6jxyjk",
        "outputId": "ea89a02b-7e9d-44fe-db49-9f9cd585e0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 2203 images loaded.\n"
          ]
        }
      ],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "imagePaths = list(paths.list_images(RMFD_PATH + \"AFDB_masked_face_dataset\"))\n",
        "\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read without-mask images"
      ],
      "metadata": {
        "id": "uunLRLW_i0ee"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYWEA60fxyjm"
      },
      "source": [
        "حال داده های موجود در مسیر داده های بدون ماسک را می خوانیم تا به صورت رندوم ۲۲۰۳ تا از آن ها را انتخاب کنیم."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5NfLoUBxyjo",
        "outputId": "1d921893-a297-4cfe-f580-8292018430f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 90468 images loaded.\n"
          ]
        }
      ],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "imagePaths = list(paths.list_images(RMFD_PATH + \"AFDB_face_dataset\"))\n",
        "\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Select 2203 random images and Creae new withou-mask images folder"
      ],
      "metadata": {
        "id": "M37KWv9Gi7qi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VqJE23Ixyjr",
        "outputId": "072cf91b-afed-4967-87dd-c71cb779e380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2203 images from AFDB_face_dataset\n"
          ]
        }
      ],
      "source": [
        "random_selected_face_dataset = random.sample(imagePaths, 2203)\n",
        "print(f'Selected {len(random_selected_face_dataset)} images from AFDB_face_dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XghOgbKPxyjv"
      },
      "source": [
        "حال باید عکس های انتخاب شده از مجموعه ی بدون ماسک را به یک فولدر دیگر انتقال دهیم تا از آن ها برای آموزش مدل استفاده شود.\n",
        "\n",
        "\n",
        "اول یک فولدر به نام withou_mask در مسیر داده های آموزشی ایجاد می کنیم و سپس داده ها را به  آنجا انتقال می دهیم. \n",
        "\n",
        "در نهایت اسم پوشه ای که شامل عکس های با ماسک هست را نیز به with_mask تغییر می دهیم تا همه ی داده های ما برچسب یکسانی داشته باشند و در کلاس بندی به مشکل نخوریم."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBU9hbz-xyjv",
        "outputId": "0143cecc-6dfa-4b0f-e553-b3e4d6fd8668"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2203/2203 [01:13<00:00, 29.92it/s]\n"
          ]
        }
      ],
      "source": [
        "for image in tqdm(random_selected_face_dataset):\n",
        "    shutil.copy(image, RMFD_PATH+\"without_mask/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ifSAPMzxyjx"
      },
      "source": [
        "حال پوشه ی شامل عکس های بدون ماسک را که خودمان ایجاد کردیم به همراه پوشه ی عکس های با ماسک را در یک مسیر جدید ذخیره می کنیم و از این به بعد از این داده های ویرایش شده استفاده می کنیم.\n",
        "\n",
        "\n",
        "حالا می خواهیم داده ها مربوط به هر دو پوشه را بخوانیم و آن ها را به فرمت numpy ذخیره کنیم."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read whole dataset and save in `.npy` format"
      ],
      "metadata": {
        "id": "yicaoqCTjGl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_RMFD.zip -d /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_RMFD"
      ],
      "metadata": {
        "id": "jCfAQFQy74En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-uKPlDT4xyjx",
        "outputId": "c6276439-c290-4532-f939-b1862f910e5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 4406 images loaded.\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DATA_DIR = \"/content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/\"\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(TRAIN_DATA_DIR + \"dataset_RMFD/dataset_RMFD\"))\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths[0].split(os.path.sep)[8]"
      ],
      "metadata": {
        "id": "vmvCUZKkou20",
        "outputId": "5b5634d1-2050-4c76-a4f2-19e50bb86cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'without_mask'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths[-1].split(os.path.sep)"
      ],
      "metadata": {
        "id": "kt4SSNJ_o8oi",
        "outputId": "87b269da-cd96-4310-96e3-91c64fff2eef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'content',\n",
              " 'drive',\n",
              " 'MyDrive',\n",
              " 'DIP_final_proj',\n",
              " 'face-mask-classifier-dataset',\n",
              " 'dataset_RMFD',\n",
              " 'dataset_RMFD',\n",
              " 'with_mask',\n",
              " 'pengguanying',\n",
              " '0_0_22.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Aop9lhUZxyjy",
        "outputId": "5b707961-0c53-4ba1-a0e9-0541aa27e9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4406/4406 [16:30<00:00,  4.45it/s]\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in tqdm(imagePaths):\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[8] # idx 8 because for `without_mask` label we have different directory\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\t# image = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dmldnynlxyj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c36a915-4e3a-431b-be67-328d84480f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmfd data shape: (4406, 224, 224, 3)\n",
            "rmfd labels shape: (4406,)\n"
          ]
        }
      ],
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "rmfd_data = np.array(data, dtype=\"float32\")\n",
        "rmfd_labels = np.array(labels)\n",
        "\n",
        "print(f'rmfd data shape: {rmfd_data.shape}')\n",
        "print(f'rmfd labels shape: {rmfd_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Opqt493Yxyj1"
      },
      "outputs": [],
      "source": [
        "np.save(f'{TRAIN_DATA_DIR}/rmfd_data.npy', rmfd_data)\n",
        "np.save(f'{TRAIN_DATA_DIR}/rmfd_labels.npy', rmfd_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXtGNnp0xyj2"
      },
      "source": [
        "## CDD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read whole dataset and save in .npy format"
      ],
      "metadata": {
        "id": "btm1AnAzjTkl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1P8QEqTxyj2"
      },
      "outputs": [],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(TRAIN_DATA_DIR + \"dataset_CDD\"))\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in tqdm(imagePaths):\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\t# image = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xN1QC9oEGL8",
        "outputId": "318fc45b-39b4-4b1c-9a91-63354a63238f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 177/4092 [00:57<01:58, 33.07it/s]/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "100%|██████████| 4092/4092 [10:42<00:00,  6.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbmcdrlGxyj4"
      },
      "outputs": [],
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "cdd_data = np.array(data, dtype=\"float32\")\n",
        "cdd_labels = np.array(labels)\n",
        "\n",
        "print(f'cdd data shape: {cdd_data.shape}')\n",
        "print(f'cdd labels shape: {cdd_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUO5Eewtxyj4"
      },
      "outputs": [],
      "source": [
        "np.save(f'{TRAIN_DATA_DIR}/cdd_data.npy', cdd_data)\n",
        "np.save(f'{TRAIN_DATA_DIR}/cdd_labels.npy', cdd_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgA16ESP9Vwx"
      },
      "source": [
        "## SMFD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read whole dataset and save in .npy format"
      ],
      "metadata": {
        "id": "12Hsb08k9Vw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_SMFD.zip -d /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_SMFD"
      ],
      "metadata": {
        "id": "NzLrwXLS9cFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phlaL4N-9Vw5",
        "outputId": "2c43ab4c-e0e9-4c64-9c73-1a46a7f41d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 1376 images loaded.\n"
          ]
        }
      ],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(TRAIN_DATA_DIR + \"dataset_SMFD/dataset_SMFD\"))\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in tqdm(imagePaths):\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\t# image = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee82ac2-b2d9-434b-a7be-261a2e674887",
        "id": "_nGV4pTN9Vw7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1376/1376 [00:09<00:00, 144.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAB8y7kG9Vw8",
        "outputId": "5d7406d9-337b-4254-b6b7-e60aeeb9c47a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smfd data shape: (1376, 224, 224, 3)\n",
            "smfd labels shape: (1376,)\n"
          ]
        }
      ],
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "smfd_data = np.array(data, dtype=\"float32\")\n",
        "smfd_labels = np.array(labels)\n",
        "\n",
        "print(f'smfd data shape: {smfd_data.shape}')\n",
        "print(f'smfd labels shape: {smfd_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3qqtwIj9Vw9"
      },
      "outputs": [],
      "source": [
        "np.save(f'{TRAIN_DATA_DIR}/smfd_data.npy', smfd_data)\n",
        "np.save(f'{TRAIN_DATA_DIR}/smfd_labels.npy', smfd_labels)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "416895f96ef60e2f435c971d354634a3cc51cef77097651df5226f2cdc1e0080"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "prepare_dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}