{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZahraDehghani99/FacemaskWearingAlertSystem/blob/main/prepare_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqoIpCwnxyjR"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tsai"
      ],
      "metadata": {
        "id": "9WJDtmta5K1p",
        "outputId": "27a3d431-a96c-46d0-bf05-70358dd4d545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tsai\n",
            "  Downloading tsai-0.3.1-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting pyts>=0.12.0\n",
            "  Downloading pyts-0.12.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastai>=2.5.6 in /usr/local/lib/python3.7/dist-packages (from tsai) (2.7.7)\n",
            "Requirement already satisfied: imbalanced-learn>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tsai) (0.8.1)\n",
            "Requirement already satisfied: psutil>=5.4.8 in /usr/local/lib/python3.7/dist-packages (from tsai) (5.4.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tsai) (21.3)\n",
            "Collecting torch<1.12,>=1.7.0\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 6.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from tsai) (21.1.3)\n",
            "Requirement already satisfied: nbformat>=5.1.3 in /usr/local/lib/python3.7/dist-packages (from tsai) (5.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (2.23.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (1.0.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (1.0.2)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (0.13.0+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (3.13)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (1.5.13)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (0.0.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (1.3.5)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (3.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai>=2.5.6->tsai) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn>=0.8.0->tsai) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn>=0.8.0->tsai) (1.1.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.1.3->tsai) (4.3.3)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.1.3->tsai) (5.1.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.1.3->tsai) (2.16.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.1.3->tsai) (4.11.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=5.1.3->tsai) (5.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=5.1.3->tsai) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=5.1.3->tsai) (4.1.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=5.1.3->tsai) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=5.1.3->tsai) (22.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=5.1.3->tsai) (3.8.1)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts>=0.12.0->tsai) (0.56.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts>=0.12.0->tsai) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts>=0.12.0->tsai) (0.39.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.5.6->tsai) (3.1.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (0.6.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (8.1.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (2.4.4)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (0.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (3.0.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (1.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (1.9.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (2.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.5.6->tsai) (2.11.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tsai) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4->fastai>=2.5.6->tsai) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.5.6->tsai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.5.6->tsai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.5.6->tsai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.5.6->tsai) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.5.6->tsai) (0.7.8)\n",
            "Collecting torchvision>=0.8.2\n",
            "  Downloading torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1 MB 42.2 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1 MB 24.9 MB/s \n",
            "\u001b[?25h  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 27.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai>=2.5.6->tsai) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4->fastai>=2.5.6->tsai) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.5.6->tsai) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.5.6->tsai) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.5.6->tsai) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai>=2.5.6->tsai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai>=2.5.6->tsai) (2022.1)\n",
            "Installing collected packages: torch, torchvision, pyts, tsai\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0+cu113\n",
            "    Uninstalling torchvision-0.13.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed pyts-0.12.0 torch-1.11.0 torchvision-0.12.0 tsai-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3XcU0LUxyjd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sys import getsizeof\n",
        "from tsai.all import *\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from imutils import paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLSIxtlxx8IK",
        "outputId": "4c424c38-5da2-4916-d7ec-e80a2b1b5628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## for unmount drive\n",
        "# from google.colab import drive\n",
        "# drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "iqWlsKR6fPRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbHETcNwxyjV"
      },
      "source": [
        "## RMFD "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make data balance"
      ],
      "metadata": {
        "id": "_VES2zOYik5w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdeGkcBIxyjY"
      },
      "source": [
        "در مقاله ذکر شده که این مجموعه دادگان شامل ۵۰۰۰ عکس باماسک و ۵۰۰۰ عکس بدون ماسک است. اما با مراجعه به صفحه ی گیت هاب مربوط به مقاله ی این دادگان، انواع مختلفی از دیتاست را مشاهده می کنیم که در برخی از آن ها تصاویر با ماسک از تصاویر بدون ماسک جدا نشده اند. تنها داده ای که نزدیک به اظهارات مقاله است [این](https://drive.google.com/file/d/1UlOk6EtiaXTHylRUx2mySgvJX9ycoeBp/view) لینک می باشد.\n",
        "\n",
        "طبق توضیحات گیت هاب این پوشه شامل ۵۰۰۰ عکس انسان های مختلف با ماسک و ۹۰۰۰۰ عکس ار انسان های مختلف بدون ماسک است. پس از دانلود این مجموعه دادگان متوجه می شویم برخلاف \n",
        "چیزی که در گیت هاب دادگان ذکر شده بود تنها ۲۲۰۳ عکس با ماسک و ۹۰۴۶۸ عکس بدون ماسک داریم. برای اینکه مانند مقاله کلاس بندی متوازنی داشته باشیم تمام  داده های با ماسک را استفاده می کنیم و به صورت رندوم ۲۲۰۳ عکس نیز ار داده های بدون ماسک انتخاب می کنیم. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnkv8pVhxyjh"
      },
      "outputs": [],
      "source": [
        "RMFD_PATH = \"/content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/RMFD/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read with-mask images"
      ],
      "metadata": {
        "id": "AsyEpgKPiwrs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVAqCT6jxyjk",
        "outputId": "ea89a02b-7e9d-44fe-db49-9f9cd585e0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 2203 images loaded.\n"
          ]
        }
      ],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "imagePaths = list(paths.list_images(RMFD_PATH + \"AFDB_masked_face_dataset\"))\n",
        "\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read without-mask images"
      ],
      "metadata": {
        "id": "uunLRLW_i0ee"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYWEA60fxyjm"
      },
      "source": [
        "حال داده های موجود در مسیر داده های بدون ماسک را می خوانیم تا به صورت رندوم ۲۲۰۳ تا از آن ها را انتخاب کنیم."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5NfLoUBxyjo",
        "outputId": "1d921893-a297-4cfe-f580-8292018430f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 90468 images loaded.\n"
          ]
        }
      ],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "imagePaths = list(paths.list_images(RMFD_PATH + \"AFDB_face_dataset\"))\n",
        "\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Select 2203 random images and Creae new withou-mask images folder"
      ],
      "metadata": {
        "id": "M37KWv9Gi7qi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VqJE23Ixyjr",
        "outputId": "072cf91b-afed-4967-87dd-c71cb779e380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2203 images from AFDB_face_dataset\n"
          ]
        }
      ],
      "source": [
        "random_selected_face_dataset = random.sample(imagePaths, 2203)\n",
        "print(f'Selected {len(random_selected_face_dataset)} images from AFDB_face_dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XghOgbKPxyjv"
      },
      "source": [
        "حال باید عکس های انتخاب شده از مجموعه ی بدون ماسک را به یک فولدر دیگر انتقال دهیم تا از آن ها برای آموزش مدل استفاده شود.\n",
        "\n",
        "\n",
        "اول یک فولدر به نام withou_mask در مسیر داده های آموزشی ایجاد می کنیم و سپس داده ها را به  آنجا انتقال می دهیم. \n",
        "\n",
        "در نهایت اسم پوشه ای که شامل عکس های با ماسک هست را نیز به with_mask تغییر می دهیم تا همه ی داده های ما برچسب یکسانی داشته باشند و در کلاس بندی به مشکل نخوریم."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBU9hbz-xyjv",
        "outputId": "0143cecc-6dfa-4b0f-e553-b3e4d6fd8668"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2203/2203 [01:13<00:00, 29.92it/s]\n"
          ]
        }
      ],
      "source": [
        "for image in tqdm(random_selected_face_dataset):\n",
        "    shutil.copy(image, RMFD_PATH+\"without_mask/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ifSAPMzxyjx"
      },
      "source": [
        "حال پوشه ی شامل عکس های بدون ماسک را که خودمان ایجاد کردیم به همراه پوشه ی عکس های با ماسک را در یک مسیر جدید ذخیره می کنیم و از این به بعد از این داده های ویرایش شده استفاده می کنیم.\n",
        "\n",
        "\n",
        "حالا می خواهیم داده ها مربوط به هر دو پوشه را بخوانیم و آن ها را به فرمت numpy ذخیره کنیم."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read whole dataset and save in `.npy` format"
      ],
      "metadata": {
        "id": "yicaoqCTjGl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -q /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_RMFD.zip -d /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_RMFD"
      ],
      "metadata": {
        "id": "jCfAQFQy74En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uKPlDT4xyjx",
        "outputId": "cd6fe850-3ef6-4ee3-f970-2d1ea2314d6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 4406 images loaded.\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DATA_DIR = \"/content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/\"\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(TRAIN_DATA_DIR + \"dataset_RMFD/dataset_RMFD\"))\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aop9lhUZxyjy",
        "outputId": "3e9416e8-e1e5-4c2e-cc09-fb5ce7b10b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4406/4406 [00:25<00:00, 172.57it/s]\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in tqdm(imagePaths):\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[8] # idx 8 because for `without_mask` label we have different directory\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\t# image = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmldnynlxyj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5ea8b2-4628-48fe-c989-ecd40bccfadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmfd data shape: (4406, 224, 224, 3)\n",
            "rmfd labels shape: (4406,)\n"
          ]
        }
      ],
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "rmfd_data = np.array(data, dtype=\"float32\")\n",
        "rmfd_labels = np.array(labels)\n",
        "\n",
        "print(f'rmfd data shape: {rmfd_data.shape}')\n",
        "print(f'rmfd labels shape: {rmfd_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'rmfd data : {bytes2GB(getsizeof(rmfd_data))} GB')"
      ],
      "metadata": {
        "id": "rYlfvbMe3kUg",
        "outputId": "49582280-d5f0-4961-d81a-c6fe24502850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmfd data : 2.47 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmfd_data = rmfd_data / 255.0"
      ],
      "metadata": {
        "id": "cw9dJ80y2wsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'rmfd data : {bytes2GB(getsizeof(rmfd_data))} GB')"
      ],
      "metadata": {
        "id": "MHEtAGWM36vt",
        "outputId": "7061f492-aa8f-47e9-bf07-e4295e28aa8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmfd data : 2.47 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opqt493Yxyj1"
      },
      "outputs": [],
      "source": [
        "np.save(f'{TRAIN_DATA_DIR}/rmfd_data.npy', rmfd_data)\n",
        "np.save(f'{TRAIN_DATA_DIR}/rmfd_labels.npy', rmfd_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXtGNnp0xyj2"
      },
      "source": [
        "## CDD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read whole dataset and save in .npy format"
      ],
      "metadata": {
        "id": "btm1AnAzjTkl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1P8QEqTxyj2"
      },
      "outputs": [],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(TRAIN_DATA_DIR + \"dataset_CDD\"))\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in tqdm(imagePaths):\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\t# image = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xN1QC9oEGL8",
        "outputId": "318fc45b-39b4-4b1c-9a91-63354a63238f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 177/4092 [00:57<01:58, 33.07it/s]/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "100%|██████████| 4092/4092 [10:42<00:00,  6.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbmcdrlGxyj4"
      },
      "outputs": [],
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "cdd_data = np.array(data, dtype=\"float32\")\n",
        "cdd_labels = np.array(labels)\n",
        "\n",
        "print(f'cdd data shape: {cdd_data.shape}')\n",
        "print(f'cdd labels shape: {cdd_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUO5Eewtxyj4"
      },
      "outputs": [],
      "source": [
        "np.save(f'{TRAIN_DATA_DIR}/cdd_data.npy', cdd_data)\n",
        "np.save(f'{TRAIN_DATA_DIR}/cdd_labels.npy', cdd_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgA16ESP9Vwx"
      },
      "source": [
        "## SMFD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read whole dataset and save in .npy format"
      ],
      "metadata": {
        "id": "12Hsb08k9Vw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_SMFD.zip -d /content/drive/MyDrive/DIP_final_proj/face-mask-classifier-dataset/dataset_SMFD"
      ],
      "metadata": {
        "id": "NzLrwXLS9cFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phlaL4N-9Vw5",
        "outputId": "2c43ab4c-e0e9-4c64-9c73-1a46a7f41d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading finished. 1376 images loaded.\n"
          ]
        }
      ],
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(TRAIN_DATA_DIR + \"dataset_SMFD/dataset_SMFD\"))\n",
        "print(f\"[INFO] loading finished. {len(imagePaths)} images loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in tqdm(imagePaths):\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image (224x224) and preprocess it\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\t# image = preprocess_input(image)\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee82ac2-b2d9-434b-a7be-261a2e674887",
        "id": "_nGV4pTN9Vw7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1376/1376 [00:09<00:00, 144.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAB8y7kG9Vw8",
        "outputId": "5d7406d9-337b-4254-b6b7-e60aeeb9c47a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smfd data shape: (1376, 224, 224, 3)\n",
            "smfd labels shape: (1376,)\n"
          ]
        }
      ],
      "source": [
        "# convert the data and labels to NumPy arrays\n",
        "smfd_data = np.array(data, dtype=\"float32\")\n",
        "smfd_labels = np.array(labels)\n",
        "\n",
        "print(f'smfd data shape: {smfd_data.shape}')\n",
        "print(f'smfd labels shape: {smfd_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3qqtwIj9Vw9"
      },
      "outputs": [],
      "source": [
        "np.save(f'{TRAIN_DATA_DIR}/smfd_data.npy', smfd_data)\n",
        "np.save(f'{TRAIN_DATA_DIR}/smfd_labels.npy', smfd_labels)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "416895f96ef60e2f435c971d354634a3cc51cef77097651df5226f2cdc1e0080"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Copy_of_prepare_dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}